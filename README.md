
# Medical Image Segmentation and Report Generation using UNet++, ResNet, and LLM

This repository provides an end-to-end pipeline for:
- Training a **UNet++ model** on medical images for segmentation and Legion Generation,
- Leveraging a **ResNet50 model** for feature extraction and Disease Prediction,
- And generating human-readable **LLM-based medical reports** from predictions.

---

## Project Structure

```
ML_PROJECT/
â”‚
â”œâ”€â”€ input/
â”‚   â””â”€â”€ PNG/
â”‚       â”œâ”€â”€ Original/                # Original colonoscopy images
â”‚       â”œâ”€â”€ Ground Truth/           # Corresponding segmentation masks
â”‚       â”œâ”€â”€ sample_original/        # Sample images for quick testing
â”‚       â””â”€â”€ sample_ground_truth/    # Sample masks
â”‚
â”œâ”€â”€ models\logs/                    # Saved model checkpoints and logs
â”œâ”€â”€ notebooks/                      # Jupyter notebooks for training and inference
â”œâ”€â”€ pre_processing_data/           # Augmented or preprocessed datasets
â”œâ”€â”€ report_outputs/                # Output text/image reports from LLM
â”œâ”€â”€ source/                         # Utility functions and core code modules
â”‚
â”œâ”€â”€ config.yaml                     # Configuration file for model & paths
â”œâ”€â”€ GroundTruth.csv                 # CSV for annotations or training metadata
â”œâ”€â”€ predict.py                      # Script to run predictions
â”œâ”€â”€ train.py                        # Script to train UNet++ model
â”œâ”€â”€ requirements.txt                # All necessary dependencies
â”œâ”€â”€ README.md                       # You're reading it!
```

---

## ðŸ”§ Setup Instructions

### Python Version: `3.12` Recommended

### Create and Activate a Virtual Environment

#### Windows:
```bash
cd path\to\ML_PROJECT
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
```

#### Linux/Mac:
```bash
cd /path/to/ML_PROJECT
python3.8 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

##  Installation

Make sure to install all dependencies:
```bash
pip install -r requirements.txt
```

---

##  Training the Model

Train the UNet++ model using:
```bash
python train.py
```
Using the `notebooks/ResNet_Model_skin_disease.ipynb` train the ResNet Model 

Model checkpoints will be saved to: `models\logs/`

---

##  Predict with the Model

Run inference on a test image:
```bash
python predict.py --test_img input/sample_original/your_test_image.png
```
You can also use the Jupyter Notebooks for the predictions

Predicted masks will be saved alongside the image or in `report_outputs/`.

---

##  Report Generation with LLMs

After prediction, run the notebook to auto-generate reports:
- ðŸ““ `notebooks/Connecting_ResNet_with_UNet_plus_and_LLM_report_generation.ipynb`

This notebook:
- Extracts visual features using ResNet50,
- Maps segmented regions to semantic classes,
- Uses an LLM (like OpenAI or HuggingFace) to generate a diagnostic report.

---

## ðŸ’¾ Sample Data Structure

```
input/PNG/
â”œâ”€â”€ Original/
â”‚   â””â”€â”€ 1.png, 2.png, ...
â”œâ”€â”€ Ground Truth/
â”‚   â””â”€â”€ 1.png, 2.png, ...
```



## ðŸ“¬ Contact

For questions or contributions, feel free to raise an issue or contact the maintainers:
1. yaseenah@buffalo.edu
2. mahmood7@buffalo.edu
3. kruthiks@buffalo.edu
---

